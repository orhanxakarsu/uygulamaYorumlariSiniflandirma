{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MODELİ İLE SINIFLANDIRMA MODELİ OLUŞTURMA #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk önce yapacağımız şey gerekli kütüphaneleri import etmek.Burada gerekli olan bütün kütüphaneler var.Sizde yoksa \n",
    "indirmeniz gerekecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,GRU,Embedding,CuDNNGRU\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from  sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada yapacağımız şey elimizde CSV formatında tuttuğumuz veriyi python \"DataFrame\"sine çevirmek.Python DataFrame özelliğini, bir nevi R dilinden kopyalamıştır.Makina Öğrenmesinde işimize bu DataFrameler çok yarar.Gerekli dökümantasyon: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html \n",
    "Bunun için read_csv fonksiyonunu kullanıyoruz.Bu veriyi kullanabileceğimiz bir formata dönüştürür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486994"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = pd.read_csv(\"data.csv\")\n",
    "bad_review =total_data[total_data[\"Review\"]==0]\n",
    "#Bu kısmı modelde iyileştirmeye gitmek için yaptım. --->\n",
    "X_ = bad_review[\"Review\"]\n",
    "y_=bad_review[\"Rating\"]\n",
    "#Buraya kadar <---\n",
    "total_data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Göründüğü gibi elimizde toplam 486.994 adet sınıflandırılmış veri var.Bu proje için gayet yeterli bir veri miktarı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3 yıldır tık demedi. :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3 yıldır kullanıyorum müthiş</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ürün bugün elime geçti çok fazla inceleme fırs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Almaya karar verdim. Hemencecik geldi. Keyifle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Günlük kullanımınızı çok çok iyi karsılıyor kı...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                             Review\n",
       "0       1                            3 yıldır tık demedi. :)\n",
       "1       1                      3 yıldır kullanıyorum müthiş \n",
       "2       1  Ürün bugün elime geçti çok fazla inceleme fırs...\n",
       "3       1  Almaya karar verdim. Hemencecik geldi. Keyifle...\n",
       "4       1  Günlük kullanımınızı çok çok iyi karsılıyor kı..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi veriye baktığımızda elimizde 2 sütunumuz var.Biri skorlar, diğeri puanlanan cümleler.Bizim bunları ayırmamız gerekiyor o yüzden X ve y adında 2 adet değişken tanımlayacağız.  **X'e cümleleri ,y'ye skorları koyacağız.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X__= total_data[\"Review\"].values\n",
    "X= np.append(X__,X_)\n",
    "y__=total_data[\"Rating\"].values\n",
    "y= np.append(y__,y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir önceki satırda veriyi skorlar ve cümleler olarak ikiye ayırmıştık.Şimdi makine öğrenmesinde çok önemli olan bir diğer özelliğe geldik. **Veriyi Train-Test olarak ayırma.** Bunu yapmamızın nedeni verinin doğruluk oranını eğittiğimiz veriden bağımsız bir şekilde ölçmek.Bunun eğitilmiş veriden bağımsız olması gerekiyor ki bize doğru bir sonuç versin.Bunun için **train_test_split** adında fonksiyon kullanacağız.Bu fonksiyon veriyi en verimli şekilde ayırır.Elimizdeki verinin %20'sini Test için ayıracağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20,random_state=41)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi veri ikiye bölünmüş durumda.Şuan yapacağımız şey veriyi **string formatından int formatına çevirmek.Bunu yapmamızın nedeni yapay sinir ağlarını sadece sayısal bir şekilde eğitebilmemizdir.Bunun için gerekli fonksiyonlar aşağıda.** num_words değişkenine de 10000 dememizin nedeni sadece en çok geçen 10bin kelimeyi alıp,gerisini yoksaymak istememizdir.Veride nadir kullanılan kelimelerin etkisini yoksaymak için bunu kullanmamız gerekiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words=10000\n",
    "tokenizer =Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Önceki satırda tokenizer adında bir sayısallaştırıcı fonksiyon oluşturduk.Bu fonksiyon sayesinde verileri string tipinden int tipine dönüştürebiliriz.Elimizdeki X_train ve X_test verilerine öyle yapacağız.Bu yaptığımız işleme **Tokenleştirme** denmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokens=tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens=tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi yapacağımız şey bir cümlenin en fazla ne kadar uzun olabileceğini seçmek.Bunu kafamızdan da sallayabiliriz ama bu fonksiyonel olmaz.Elimizdeki veri durumuna göre hesaplama yapmamız lazım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens=[len(tokens) for tokens in X_train_tokens + X_test_tokens]\n",
    "num_tokens=np.array(num_tokens)\n",
    "max_tokens= np.mean(num_tokens)+ np.std(num_tokens)*2\n",
    "max_tokens=int(max_tokens)\n",
    "\n",
    "X_train_pad =pad_sequences(X_train_tokens,maxlen=max_tokens)\n",
    "X_test_pad =pad_sequences(X_test_tokens,maxlen=max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu verisetine göre en iyi sonucu 59 karaktere kadar sınırlaştırırsak alırız.Cümle sayısı 59'dan küçük olan cümlelerin sonuna 0 koyar, büyük olan cümlelerin de 59'dan sonrasını siler.Bu bizim modelimizi daha optimal yapar hem de gereksiz uzunluktan bizi kurtarır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Şimdi sıra model oluşturmada #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_size = 50\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name=\"embedding_layer\"))\n",
    "#Burada LSTM modelinin bir türü olan GRU'yu kullanacağız.İkisinden de aynı değerleri alırız fakat GRU daha optimize çalışır.\n",
    "#Önceki tespitlerime göre 2 derin ağ 16-8 olarak bu veride en optimal çalışıyor.O yüzden 3 katman ekliyoruz.\n",
    "model.add(GRU(units=16,return_sequences=True))\n",
    "model.add(GRU(units=8))\n",
    "\"\"\"Şimdi derin ağlarımızı oluşturduk.Çıkış ağına da sigmoid =(1/(1+e^(-x) )) fonksiyonu kullanıyoruz.\n",
    "Bu fonksiyon gelen değerleri 0 ile 1 olarak döndürür.Yani en yüksek tahmin skorlarını 1'e yaklaştırır.\n",
    "En düşüklerini 0'a.Bu özellik te bize cümlelerini sınıflandırma şansı verir. \"\"\"\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "               metrics=[\"accuracy\"])\n",
    "#Optimizer = Geriye yayılım sırasında kullanılacak fonksiyon.Bu modelin parametrelerinin en iyi şekilde olmasına yarıyor.\n",
    "#metrics = Doğruluğu %sel olarak gösterecek fonksiyon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 59, 50)            500000    \n",
      "_________________________________________________________________\n",
      "gru_21 (GRU)                 (None, 59, 16)            3216      \n",
      "_________________________________________________________________\n",
      "gru_22 (GRU)                 (None, 8)                 600       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 503,825\n",
      "Trainable params: 503,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #Model hakkında tüm bilgi burada yazar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Şimdi sıra modelimizi eğitmekte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 'un anlamı aynı veriyi modele tekrar tekrar vermektir.Bu öğrenmeyi iyi bir şekilde arttırır.Fakat bazı sorunları vardır.Sayıyı çok tutarsak **overfitting (aşırı öğrenme)** dediğimiz bir sorun ortaya çıkarır.O yüzden 3 bu verinin çapına göre en iyi rakamdır.İyi bir öğrenme sunar hem de modelin başarıyla çalışmasını sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194797 samples\n",
      "Epoch 1/3\n",
      "194797/194797 [==============================] - 98s 504us/sample - loss: 0.1529 - accuracy: 0.9539\n",
      "Epoch 2/3\n",
      "194797/194797 [==============================] - 97s 499us/sample - loss: 0.0917 - accuracy: 0.9681\n",
      "Epoch 3/3\n",
      "194797/194797 [==============================] - 98s 501us/sample - loss: 0.0762 - accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22037998848>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad,y_train,epochs=3,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelimizi eğittik.İlk bakışta %97.3 başarı oranı, % 0.76 kayıp oranımız var.Bu çok iyi bir değer.Şimdi test için ayırdığımız veride de başarı oranımızı hesaplayacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48700/48700 [==============================] - 33s 670us/sample - loss: 0.1092 - accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10919102820986595, 0.96455854]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_pad,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, 95 = 1 ,5 =0 y_tahmin 93=1, 7=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğittiğimiz veriden bağımsız doğruluk sonucumuz da % 96 .Şimdi 1-2 yorum denemesi yapalım.Bunun için bir fonksiyon yapacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tahmin(cumleler):\n",
    "    tokens=tokenizer.texts_to_sequences(cumleler)\n",
    "    tokens_pad = pad_sequences(tokens,maxlen=max_tokens)\n",
    "    tahmin =model.predict(tokens_pad)\n",
    "    print(tahmin)\n",
    "    if tahmin>0.45 and tahmin<0.65:\n",
    "        print(\"Bu cümle nötrdür.\")\n",
    "    elif tahmin <0.40 :\n",
    "        print(\"Bu cümle olumsuzdur.\")\n",
    "    elif tahmin > 0.60 :\n",
    "        print(\"Bu cümle olumludur.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2997198]]\n",
      "Bu cümle olumsuzdur.\n"
     ]
    }
   ],
   "source": [
    "cumle = [\"Bu kadar dandik bi uygulama. Bu kadar zor ve anlaşılması imkansız bi saçma uygulama görmedim. Yahu bi mobil uygulamada kredi kartı başvurusunu yapamadım saatlerdir uğraşıyorumş\"]\n",
    "tahmin(cumle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.91844386]]\n",
      "Bu cümle olumludur.\n"
     ]
    }
   ],
   "source": [
    "cumle =[\"Pek benlik değil ama gene de iyi\"]\n",
    "tahmin(cumle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05859238]]\n",
      "Bu cümle olumsuzdur.\n"
     ]
    }
   ],
   "source": [
    "cumle =[\"Çok kalitesiz duruyor\"]\n",
    "tahmin(cumle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99264973]]\n",
      "Bu cümle olumludur.\n"
     ]
    }
   ],
   "source": [
    "cumle =[\"Uygulamadan gayet memnun kaldım\"]\n",
    "tahmin(cumle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Şimdi model ağırlıklarını kaydedelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"review_classification.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *SON*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
